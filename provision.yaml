---
# code: language=ansible
# vim:syntax=yaml
## This playbook deploys server on BMC using the ramOS method

- name: Provision BMC servers
  hosts: servers
  strategy: linear
  gather_facts: false
  vars_files:
    - ~/.pnap/config.yaml
  collections:
  - phoenixnap.bmc
  tags:
    - provision
  tasks:
  - name: Provisioning server
    delegate_to: localhost
    register: result
    phoenixnap.bmc.server:
      client_id: "{{clientId}}"
      client_secret: "{{clientSecret}}"
      hostnames: "{{ inventory_hostname }}"
      location: "{{ hostvars[inventory_hostname].location }}"
      os: "{{ hostvars[inventory_hostname].os }}"
      type: "{{ hostvars[inventory_hostname].type }}"
      description: "{{ hostvars[inventory_hostname].description }}"
      install_default_sshkeys: "{{ hostvars[inventory_hostname].install_default_ssh_keys }}"
      ssh_key: "{{ hostvars[inventory_hostname].ssh_key }}"
      ssh_key_ids: "{{ hostvars[inventory_hostname].ssh_key_ids }}"
      reservation_id: "{{ hostvars[inventory_hostname].reservation_id }}"
      pricing_model: "{{ hostvars[inventory_hostname].pricing_model }}"
      network_type: "{{ hostvars[inventory_hostname].network_type }}"
      # private_network_configuration_type: USER_DEFINED
      # private_network_gateway_address: "{{ hostvars[inventory_hostname].network_gateway }}"
      # private_networks:
      #   - id: "{{ hostvars[inventory_hostname].network }}"
      #     ips: "{{ hostvars[inventory_hostname].network_ips }}"
      #     dhcp: false
      install_os_to_ram: true
      state: present
    retries: 1
    delay: 3
    until: (not result.failed) and (result.servers is defined)

  - name: Print out relevant response
    debug:
      var: result
    tags: 
      - debug

  - name: Set ansible_host to public IP address
    set_fact:
      ansible_host: "{{ result.servers.0.publicIpAddresses.0 }}"

  # - name: Set ansible_host to private IP address
  #   set_fact:
  #     ansible_host: "{{ result.servers.0.privateIpAddresses.0 }}"

- name: Perform work on provisioned BMC servers
  hosts: servers
  gather_facts: false
  become: true
  vars:
    ansible_user: ubuntu
    ansible_connection: ssh
    host_key_checking: false
    accelerate: true
    os_url: "{{ hostvars[inventory_hostname].os_url }}" 
    admin_password: "{{ hostvars[inventory_hostname].admin_password }}"

  tasks:
  - name: Wait for SSH connection
    wait_for_connection:
      sleep: 1
      connect_timeout: 5
      timeout: 60
  - name: write resolved.conf
    copy:
      dest: /tmp/cloud-init.yaml
      content: |  
        [Resolve]
        DNS={{ hostvars[inventory_hostname].network_dns }}
    register: resolveConf
    retries: 3
    until: resolveConf is not failed

  - name: restart systemd-resolved
    command: |
      systemctl restart systemd-resolved
    register: restart_resolved

  - name: Install tools
    apt:
      pkg:
        - zfsutils-linux
        - fdisk
    # no_log: true
    register: install
    retries: 3
    until: install is not failed

  - name: Capture block devices on server
    command: "lsblk  --tree -J -o KNAME,PATH,RO,SIZE,TYPE -x KNAME"
    register: res_block_devices
    no_log: true
  
  - name: Get Network Configuration
    command: "cat /etc/cloud/cloud.cfg.d/50-curtin-networking.cfg"
    register: net_config
    no_log: true
  
  - name: get ethernet settings
    set_fact:
      ethernets: "{{ (net_config.stdout | from_yaml).network.ethernets }}"
  
  - name: get bond settings
    set_fact:
      bond: "{{ (net_config.stdout | from_yaml).network.bonds.bond0 }}"

  - name: get vlans
    set_fact:
      vlans: "{{ (net_config.stdout | from_yaml).network.vlans }}"

  - name: Filter block devices (non-readonly disks)
    set_fact:
      block_devices: "{{ (res_block_devices.stdout | from_json).blockdevices | rejectattr('ro','equalto','true') | selectattr('type', 'equalto', 'disk') | rejectattr('kname','equalto','vda')}}"
  
  - name: Get disk device nodes
    set_fact:
      disks: "{{ block_devices | map(attribute='path') }}"

  - name: Detect boot mode
    shell: |
      [ -d /sys/firmware/efi ] &&  echo UEFI || echo Legacy
    register: os_boot_mode

  - name: prod
    set_fact:
      prod: "{{ (vlans | dict2items | selectattr('value', 'contains', 'routes'))[0] }}"
  
  # - name: Print prod
  #   debug:
  #     var: prod

  - name: write hive cloud-init
    copy:
      dest: /tmp/cloud-init.yaml
      content: |
        #cloud-config
          hiveio:
            fbw:
              version: 1
              eula: true
              hostname: {{ inventory_hostname }}
              password: {{ admin_password }}
              network:
                bond:
                  nics: {{ bond.interfaces }}
                  mode: {{ bond.parameters.mode }}
                  hashPolicy: {{ bond.parameters['transmit-hash-policy'] }}
                prod:
                  dhcp: false
                  interface: {{ bond.interfaces[0] }}
                  vlan : {{ prod.value.id }}
                  address: {{ prod.value.addresses[0] | ipaddr('address') }}
                  netmask: {{ prod.value.addresses[0] | ipaddr('netmask') }}
                  gateway: {{ prod.value.routes[0].via }}
                  dns: {{ hostvars[inventory_hostname].network_dns }}
                storage:
                  disabled: true

  - name: write install script
    copy:
      dest: /tmp/install.sh
      mode: a+x
      content: |
        #!/bin/bash -ex
        POOL=zpool
        function setupChroot() {
          MNT=$1
          if [ -z "$MNT" ]; then
            return 1
          fi
          mount --bind /dev "$MNT/dev"
          mount --bind /sys "$MNT/sys"
          mount --bind /proc "$MNT/proc"
        }

        function cleanupChroot() {
          MNT=$1
          if [ -z "$MNT" ]; then
            return 1
          fi
          umount -f "$MNT/proc"
          umount -f "$MNT/sys"
          umount -f "$MNT/dev"
        }

        function cleanup() {
          cleanupChroot /mnt
          zfs umount -a
          zpool export zpool
        }

        function hasEFI() {
          if [ -d "/sys/firmware/efi" ]; then
            return 0
          fi
          return 1
        }

        function efiPartition() {
          DISK="$1"
          lsblk -rp "$DISK" -o NAME,PARTUUID,PARTTYPE | grep -i c12a7328-f81f-11d2-ba4b-00a0c93ec93b | awk '{print $1}'
        }

        function zfsPartition() {
          DISK="$1"
          if hasEFI; then
            lsblk -rp "$DISK" -o NAME,PARTUUID,PARTTYPE | grep -i 6A85CF4D-1DD2-11B2-99A6-080020736631 | awk '{print $1}'
          else
            lsblk -rp "$DISK" | grep part | awk '{print $1}'
          fi
        }

        function installGrub() {
          GRUB_DISK="$1"
          if hasEFI; then
            GRUB_PARTITION="$(efiPartition "$GRUB_DISK")"
            chroot /mnt mkfs.vfat "$GRUB_PARTITION"
            mkdir -p /mnt/boot/efi
            mount "$GRUB_PARTITION" /mnt/boot/efi
            chroot /mnt update-initramfs -u -k all
            chroot /mnt update-grub
            chroot /mnt grub-install --target=x86_64-efi --efi-directory=/boot/efi \
                  --bootloader-id=hiveio --recheck --no-floppy || errorMessage "Failed to install boot loader"
            umount "$GRUB_PARTITION"
            for DISK in {{disks | join(' ')}}; do
              [ "${DISK}" = "${GRUB_DISK}" ] && continue
              PART="$(efiPartition "$DISK")"
              dd if="$GRUB_PARTITION" of="$PART"
            done
          else
            DISKS="$(lsblk -dp | grep disk | grep -v "${BOOT_DISK}" | awk '{print $1}')"
            chroot /mnt update-initramfs -u -k all
            chroot /mnt update-grub
            GRUB_INSTALLED=false
            for DISK in {{disks | join(' ')}}; do
              chroot /mnt grub-install "${DISK}" && GRUB_INSTALLED=true
            done
            if ! $GRUB_INSTALLED; then
              errorMessage  "Failed to install boot loader"
            fi
          fi
        }
        
        {% for disk in disks %}
        DISK="{{ disk }}"
        sgdisk --zap-all "${DISK}" || true
        if hasEFI; then
          sgdisk -n1:1M:+32M -t1:EF00 -N2 -t2:BF00 "$DISK"
        else
          echo ",,83;" | sfdisk --force "$DISK"
        fi
        udevadm trigger
        udevadm settle
        ZDEV="$(zfsPartition "$DISK")"
        if [ -n "$ZDEV" ]; then
          ZDEVS+=" $ZDEV"
        fi
        {% endfor %}

        #DISKS="{{ block_devices | map(attribute='path') | join(' ') }}"
        zpool create -f -o ashift=12 \
              -O atime=off -O canmount=off -O compression=lz4  \
              -O xattr=sa -O mountpoint=/ -R /mnt \
              "${POOL}"  $ZDEVS

        if [ "$?" -ne 0 ]; then
          echo "Error: Failed to create zpool"
          exit 1
        fi

        #rootfs
        zfs create -o canmount=noauto -o mountpoint=/ "${POOL}/root"
        zpool set "bootfs=${POOL}/root" "${POOL}"
        zfs mount "${POOL}/root"

        # zdata
        zfs create "${POOL}/zdata"
        zfs set compression=lz4 "${POOL}/zdata"
        zfs set mountpoint=/zdata "${POOL}/zdata"

        # rethinkDB storage
        zfs create "${POOL}/rethink"
        zfs set compression=lz4 "${POOL}/rethink"
        zfs set mountpoint=/var/lib/rethinkdb/hive "${POOL}/rethink"

        # /opt/hive
        zfs create "${POOL}/hive"
        zfs set compression=lz4 "${POOL}/hive"
        zfs set mountpoint=/opt/hive "${POOL}/hive"
        
        # /opt/hive/conf
        zfs create ${POOL}/hive/conf
        zfs set compression=lz4 ${POOL}/hive/conf
        zfs set mountpoint=/opt/hive/conf ${POOL}/hive/conf
        
        curl -k "{{os_image_url}}" | xzcat -T 0 | tar -xC /mnt/
        setupChroot /mnt
        installGrub "{{disks[0]}}"
        cp /etc/cloud/cloud.cfg.d/50-curtin-networking.cfg /mnt/etc/cloud/cloud.cfg.d/
        SNAPSHOT="$(basename /mnt/opt/hive/build/hiveio-fabric-*.pkg .pkg| sed 's/hiveio-fabric-v//')"
        zfs snapshot "zpool/root@${SNAPSHOT}"
        zfs snapshot "zpool/hive@${SNAPSHOT}"
        zfs snapshot "zpool/hive/conf@${SNAPSHOT}"
        
        echo "datasource: NoCloud, None" >> /etc/cloud/ds-identify.cfg
        echo "policy: enabled" >> /etc/cloud/ds-identify.cfg
        echo "datasource_list: [ NoCloud, None ]" > /mnt/etc/cloud/cloud.cfg.d/95-cloudconfig-datasource.cfg

        mkdir -p /mnt/home/admin1/
        #cp -r /home/ubuntu/.ssh /mnt/home/admin1/
        cp /tmp/cloud-init.yaml /mnt/etc/cloud/cloud.cfg.d/90-fabric-config.cfg
        cleanup
  - name: Install
    command: "/tmp/install.sh"

  - name: Reboot
    command: "reboot"
    async: 300
    poll: 0

  # - name: "Switch to {{ os_user }} user"
  #   set_fact: 
  #     ansible_user: "{{ os_user }}"
  #     ansible_ssh_pass: "{{ admin_password }}"
  
  # - name: Wait for SSH connection after reboot
  #   wait_for_connection:
  #     delay: 60
  #     sleep: 1
  #     connect_timeout: 5
  #     timeout: 600

  # - name: Report from deployed OS
  #   shell: "hostname; uname -a; ip a"
